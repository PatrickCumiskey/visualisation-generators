{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Generation Scripts\n",
    "\n",
    "Edit the variables below and run the cells in order to generate graph files that can be opened in Gephi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: appnope==0.1.0 in /Users/duncan/venv/jupyter/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (0.1.0)\n",
      "Requirement already satisfied: attrs==19.3.0 in /Users/duncan/venv/jupyter/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (19.3.0)\n",
      "Requirement already satisfied: backcall==0.1.0 in /Users/duncan/venv/jupyter/lib/python3.6/site-packages (from -r requirements.txt (line 3)) (0.1.0)\n",
      "Collecting beautifulsoup4==4.8.2 (from -r requirements.txt (line 4))\n",
      "  Using cached https://files.pythonhosted.org/packages/cb/a1/c698cf319e9cfed6b17376281bd0efc6bfc8465698f54170ef60a485ab5d/beautifulsoup4-4.8.2-py3-none-any.whl\n",
      "Collecting bleach==3.1.0 (from -r requirements.txt (line 5))\n",
      "  Using cached https://files.pythonhosted.org/packages/ab/05/27e1466475e816d3001efb6e0a85a819be17411420494a1e602c36f8299d/bleach-3.1.0-py2.py3-none-any.whl\n",
      "Collecting bs4==0.0.1 (from -r requirements.txt (line 6))\n",
      "Collecting decorator==4.4.1 (from -r requirements.txt (line 7))\n",
      "  Using cached https://files.pythonhosted.org/packages/8f/b7/f329cfdc75f3d28d12c65980e4469e2fa373f1953f5df6e370e84ea2e875/decorator-4.4.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: defusedxml==0.6.0 in /Users/duncan/venv/jupyter/lib/python3.6/site-packages (from -r requirements.txt (line 8)) (0.6.0)\n",
      "Requirement already satisfied: entrypoints==0.3 in /Users/duncan/venv/jupyter/lib/python3.6/site-packages (from -r requirements.txt (line 9)) (0.3)\n",
      "Collecting geomdl==5.2.9 (from -r requirements.txt (line 10))\n",
      "  Using cached https://files.pythonhosted.org/packages/b0/95/38152ca47b749553d2ff93fe2ad6cbe9d724ced152c0a48b5ba2a13a3f83/geomdl-5.2.9-py2.py3-none-any.whl\n",
      "Collecting importlib-metadata==1.4.0 (from -r requirements.txt (line 11))\n",
      "  Using cached https://files.pythonhosted.org/packages/d7/31/74dcb59a601b95fce3b0334e8fc9db758f78e43075f22aeb3677dfb19f4c/importlib_metadata-1.4.0-py2.py3-none-any.whl\n",
      "Collecting ipykernel==5.1.3 (from -r requirements.txt (line 12))\n",
      "  Using cached https://files.pythonhosted.org/packages/e1/92/8fec943b5b81078399f969f00557804d884c96fcd0bc296e81a2ed4fd270/ipykernel-5.1.3-py3-none-any.whl\n",
      "Collecting ipython==7.11.1 (from -r requirements.txt (line 13))\n",
      "  Using cached https://files.pythonhosted.org/packages/1c/f3/c8be38ee117d02508bb8b9158eb41ca416f442a6e8e3b3159c2f2d14ed79/ipython-7.11.1-py3-none-any.whl\n",
      "Requirement already satisfied: ipython-genutils==0.2.0 in /Users/duncan/venv/jupyter/lib/python3.6/site-packages (from -r requirements.txt (line 14)) (0.2.0)\n",
      "Collecting jedi==0.15.2 (from -r requirements.txt (line 15))\n",
      "  Using cached https://files.pythonhosted.org/packages/e9/97/55e575a5b49e5c3df9eb3c116c61021d7badf556c816be13bbd7baf55234/jedi-0.15.2-py2.py3-none-any.whl\n",
      "Collecting Jinja2==2.10.3 (from -r requirements.txt (line 16))\n",
      "  Using cached https://files.pythonhosted.org/packages/65/e0/eb35e762802015cab1ccee04e8a277b03f1d8e53da3ec3106882ec42558b/Jinja2-2.10.3-py2.py3-none-any.whl\n",
      "Collecting json5==0.8.5 (from -r requirements.txt (line 17))\n",
      "  Using cached https://files.pythonhosted.org/packages/30/44/062543d4a6718f99d82e5ecf9140dbdee8a03122f2c34fbd0b0609891707/json5-0.8.5-py2.py3-none-any.whl\n",
      "Requirement already satisfied: jsonschema==3.2.0 in /Users/duncan/venv/jupyter/lib/python3.6/site-packages (from -r requirements.txt (line 18)) (3.2.0)\n",
      "Collecting jupyter-client==5.3.4 (from -r requirements.txt (line 19))\n",
      "  Using cached https://files.pythonhosted.org/packages/13/81/fe0eee1bcf949851a120254b1f530ae1e01bdde2d3ab9710c6ff81525061/jupyter_client-5.3.4-py2.py3-none-any.whl\n",
      "Collecting jupyter-core==4.6.1 (from -r requirements.txt (line 20))\n",
      "  Using cached https://files.pythonhosted.org/packages/fb/82/86437f661875e30682e99d04c13ba6c216f86f5f6ca6ef212d3ee8b6ca11/jupyter_core-4.6.1-py2.py3-none-any.whl\n",
      "Collecting jupyterlab==1.2.5 (from -r requirements.txt (line 21))\n",
      "  Using cached https://files.pythonhosted.org/packages/50/a5/09acfaf5a43b1aa42c529dd8b5bb63552a0efc0e35a03febbe44e94d8225/jupyterlab-1.2.5-py2.py3-none-any.whl\n",
      "Collecting jupyterlab-server==1.0.6 (from -r requirements.txt (line 22))\n",
      "  Using cached https://files.pythonhosted.org/packages/78/98/5b87b9d38176bd98f23b58a8fb730e5124618d68571a011abbd38ad4a842/jupyterlab_server-1.0.6-py3-none-any.whl\n",
      "Collecting lxml==4.4.2 (from -r requirements.txt (line 23))\n",
      "  Using cached https://files.pythonhosted.org/packages/50/a4/fb2c4441028bc81d3b50f970a8471ac5b34e64fcc85d5dc304691b0c41ff/lxml-4.4.2-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n",
      "Requirement already satisfied: MarkupSafe==1.1.1 in /Users/duncan/venv/jupyter/lib/python3.6/site-packages (from -r requirements.txt (line 24)) (1.1.1)\n",
      "Requirement already satisfied: mistune==0.8.4 in /Users/duncan/venv/jupyter/lib/python3.6/site-packages (from -r requirements.txt (line 25)) (0.8.4)\n",
      "Collecting more-itertools==8.1.0 (from -r requirements.txt (line 26))\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/e2/3206a70758a21f9878fcf9478282bb68fbc66a5564718f9ed724c3f2bb52/more_itertools-8.1.0-py3-none-any.whl\n",
      "Requirement already satisfied: nbconvert==5.6.1 in /Users/duncan/venv/jupyter/lib/python3.6/site-packages (from -r requirements.txt (line 27)) (5.6.1)\n",
      "Collecting nbformat==5.0.3 (from -r requirements.txt (line 28))\n",
      "  Using cached https://files.pythonhosted.org/packages/5d/69/87745d03d1964649ef734238b32bf08eb843a6594cb03e8bc77edc8f33e9/nbformat-5.0.3-py3-none-any.whl\n",
      "Collecting nbstripout==0.3.7 (from -r requirements.txt (line 29))\n",
      "  Using cached https://files.pythonhosted.org/packages/6d/b8/9ca6e80ba7e676554e07b48554b7412132309702cdd296152e6151b22510/nbstripout-0.3.7-py2.py3-none-any.whl\n",
      "Collecting networkx==2.4 (from -r requirements.txt (line 30))\n",
      "  Using cached https://files.pythonhosted.org/packages/41/8f/dd6a8e85946def36e4f2c69c84219af0fa5e832b018c970e92f2ad337e45/networkx-2.4-py3-none-any.whl\n",
      "Collecting notebook==6.0.2 (from -r requirements.txt (line 31))\n",
      "  Using cached https://files.pythonhosted.org/packages/f5/69/d2ffaf7efc20ce47469187e3a41e6e03e17b45de5a6559f4e7ab3eace5e1/notebook-6.0.2-py3-none-any.whl\n",
      "Collecting numpy==1.18.1 (from -r requirements.txt (line 32))\n",
      "  Using cached https://files.pythonhosted.org/packages/82/63/eee643cc97f2bd22da87420f28fb6cd4b940c25f6eff6c4d2ca2e24a7022/numpy-1.18.1-cp36-cp36m-macosx_10_9_x86_64.whl\n",
      "Requirement already satisfied: pandocfilters==1.4.2 in /Users/duncan/venv/jupyter/lib/python3.6/site-packages (from -r requirements.txt (line 33)) (1.4.2)\n",
      "Collecting parso==0.5.2 (from -r requirements.txt (line 34))\n",
      "  Using cached https://files.pythonhosted.org/packages/9b/b0/90353a5ece0987279837835224dead0c424833a224195683e188d384e06b/parso-0.5.2-py2.py3-none-any.whl\n",
      "Collecting pexpect==4.7.0 (from -r requirements.txt (line 35))\n",
      "  Using cached https://files.pythonhosted.org/packages/0e/3e/377007e3f36ec42f1b84ec322ee12141a9e10d808312e5738f52f80a232c/pexpect-4.7.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pickleshare==0.7.5 in /Users/duncan/venv/jupyter/lib/python3.6/site-packages (from -r requirements.txt (line 36)) (0.7.5)\n",
      "Requirement already satisfied: prometheus-client==0.7.1 in /Users/duncan/venv/jupyter/lib/python3.6/site-packages (from -r requirements.txt (line 37)) (0.7.1)\n",
      "Collecting prompt-toolkit==3.0.2 (from -r requirements.txt (line 38))\n",
      "  Using cached https://files.pythonhosted.org/packages/7f/1f/e145dd467dc9b0e6f1e64232c03119498dfec497e383f1e8be9f83eaa97e/prompt_toolkit-3.0.2-py3-none-any.whl\n",
      "Requirement already satisfied: ptyprocess==0.6.0 in /Users/duncan/venv/jupyter/lib/python3.6/site-packages (from -r requirements.txt (line 39)) (0.6.0)\n",
      "Collecting Pygments==2.5.2 (from -r requirements.txt (line 40))\n",
      "  Using cached https://files.pythonhosted.org/packages/be/39/32da3184734730c0e4d3fa3b2b5872104668ad6dc1b5a73d8e477e5fe967/Pygments-2.5.2-py2.py3-none-any.whl\n",
      "Collecting pyparsing==2.4.6 (from -r requirements.txt (line 41))\n",
      "  Using cached https://files.pythonhosted.org/packages/5d/bc/1e58593167fade7b544bfe9502a26dc860940a79ab306e651e7f13be68c2/pyparsing-2.4.6-py2.py3-none-any.whl\n",
      "Collecting pyrsistent==0.15.7 (from -r requirements.txt (line 42))\n",
      "Requirement already satisfied: python-dateutil==2.8.1 in /Users/duncan/venv/jupyter/lib/python3.6/site-packages (from -r requirements.txt (line 43)) (2.8.1)\n",
      "Collecting pyzmq==18.1.1 (from -r requirements.txt (line 44))\n",
      "  Using cached https://files.pythonhosted.org/packages/18/39/e87911d58bfe63a0ec0a37fc529548d8278dc7ba094045ae4c095267a602/pyzmq-18.1.1-cp36-cp36m-macosx_10_6_intel.whl\n",
      "Requirement already satisfied: Send2Trash==1.5.0 in /Users/duncan/venv/jupyter/lib/python3.6/site-packages (from -r requirements.txt (line 45)) (1.5.0)\n",
      "Collecting Shapely==1.6.4.post2 (from -r requirements.txt (line 46))\n",
      "  Using cached https://files.pythonhosted.org/packages/cf/f8/110690b7c44b9418f573e351084c23d33d782f84416bdb179f1b0f9f401c/Shapely-1.6.4.post2-cp36-cp36m-macosx_10_9_x86_64.whl\n",
      "Requirement already satisfied: six==1.14.0 in /Users/duncan/venv/jupyter/lib/python3.6/site-packages (from -r requirements.txt (line 47)) (1.14.0)\n",
      "Collecting soupsieve==1.9.5 (from -r requirements.txt (line 48))\n",
      "  Using cached https://files.pythonhosted.org/packages/81/94/03c0f04471fc245d08d0a99f7946ac228ca98da4fa75796c507f61e688c2/soupsieve-1.9.5-py2.py3-none-any.whl\n",
      "Collecting svgwrite==1.3.1 (from -r requirements.txt (line 49))\n",
      "  Using cached https://files.pythonhosted.org/packages/4f/2e/f36cfec1da6162055b884e6366074cff18475a9538559ceae0c0bc58e186/svgwrite-1.3.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: terminado==0.8.3 in /Users/duncan/venv/jupyter/lib/python3.6/site-packages (from -r requirements.txt (line 50)) (0.8.3)\n",
      "Requirement already satisfied: testpath==0.4.4 in /Users/duncan/venv/jupyter/lib/python3.6/site-packages (from -r requirements.txt (line 51)) (0.4.4)\n",
      "Collecting tornado==6.0.3 (from -r requirements.txt (line 52))\n",
      "Requirement already satisfied: traitlets==4.3.3 in /Users/duncan/venv/jupyter/lib/python3.6/site-packages (from -r requirements.txt (line 53)) (4.3.3)\n",
      "Collecting Wand==0.5.8 (from -r requirements.txt (line 54))\n",
      "  Using cached https://files.pythonhosted.org/packages/ad/4a/6d4897ce1c6640c0669829d34cdf956e0829281b3f94c71effdb23bdde3c/Wand-0.5.8-py2.py3-none-any.whl\n",
      "Collecting wcwidth==0.1.8 (from -r requirements.txt (line 55))\n",
      "  Using cached https://files.pythonhosted.org/packages/58/b4/4850a0ccc6f567cc0ebe7060d20ffd4258b8210efadc259da62dc6ed9c65/wcwidth-0.1.8-py2.py3-none-any.whl\n",
      "Requirement already satisfied: webencodings==0.5.1 in /Users/duncan/venv/jupyter/lib/python3.6/site-packages (from -r requirements.txt (line 56)) (0.5.1)\n",
      "Collecting zipp==1.0.0 (from -r requirements.txt (line 57))\n",
      "  Using cached https://files.pythonhosted.org/packages/f4/50/cc72c5bcd48f6e98219fc4a88a5227e9e28b81637a99c49feba1d51f4d50/zipp-1.0.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: setuptools>=18.5 in /Users/duncan/venv/jupyter/lib/python3.6/site-packages (from ipython==7.11.1->-r requirements.txt (line 13)) (39.0.1)\n",
      "Installing collected packages: soupsieve, beautifulsoup4, bleach, bs4, decorator, geomdl, more-itertools, zipp, importlib-metadata, tornado, jupyter-core, pyzmq, jupyter-client, wcwidth, prompt-toolkit, Pygments, parso, jedi, pexpect, ipython, ipykernel, Jinja2, json5, nbformat, notebook, jupyterlab-server, jupyterlab, lxml, nbstripout, networkx, numpy, pyparsing, pyrsistent, Shapely, svgwrite, Wand\n",
      "  Found existing installation: bleach 3.1.4\n",
      "    Uninstalling bleach-3.1.4:\n",
      "      Successfully uninstalled bleach-3.1.4\n",
      "  Found existing installation: decorator 4.4.2\n",
      "    Uninstalling decorator-4.4.2:\n",
      "      Successfully uninstalled decorator-4.4.2\n",
      "  Found existing installation: zipp 3.1.0\n",
      "    Uninstalling zipp-3.1.0:\n",
      "      Successfully uninstalled zipp-3.1.0\n",
      "  Found existing installation: importlib-metadata 1.6.0\n",
      "    Uninstalling importlib-metadata-1.6.0:\n",
      "      Successfully uninstalled importlib-metadata-1.6.0\n",
      "  Found existing installation: tornado 6.0.4\n",
      "    Uninstalling tornado-6.0.4:\n",
      "      Successfully uninstalled tornado-6.0.4\n",
      "  Found existing installation: jupyter-core 4.6.3\n",
      "    Uninstalling jupyter-core-4.6.3:\n",
      "      Successfully uninstalled jupyter-core-4.6.3\n",
      "  Found existing installation: pyzmq 19.0.0\n",
      "    Uninstalling pyzmq-19.0.0:\n",
      "      Successfully uninstalled pyzmq-19.0.0\n",
      "  Found existing installation: jupyter-client 6.1.2\n",
      "    Uninstalling jupyter-client-6.1.2:\n",
      "      Successfully uninstalled jupyter-client-6.1.2\n",
      "  Found existing installation: wcwidth 0.1.9\n",
      "    Uninstalling wcwidth-0.1.9:\n",
      "      Successfully uninstalled wcwidth-0.1.9\n",
      "  Found existing installation: prompt-toolkit 3.0.5\n",
      "    Uninstalling prompt-toolkit-3.0.5:\n",
      "      Successfully uninstalled prompt-toolkit-3.0.5\n",
      "  Found existing installation: Pygments 2.6.1\n",
      "    Uninstalling Pygments-2.6.1:\n",
      "      Successfully uninstalled Pygments-2.6.1\n",
      "  Found existing installation: parso 0.6.2\n",
      "    Uninstalling parso-0.6.2:\n",
      "      Successfully uninstalled parso-0.6.2\n",
      "  Found existing installation: jedi 0.16.0\n",
      "    Uninstalling jedi-0.16.0:\n",
      "      Successfully uninstalled jedi-0.16.0\n",
      "  Found existing installation: pexpect 4.8.0\n",
      "    Uninstalling pexpect-4.8.0:\n",
      "      Successfully uninstalled pexpect-4.8.0\n",
      "  Found existing installation: ipython 7.13.0\n",
      "    Uninstalling ipython-7.13.0:\n",
      "      Successfully uninstalled ipython-7.13.0\n",
      "  Found existing installation: ipykernel 5.2.0\n",
      "    Uninstalling ipykernel-5.2.0:\n",
      "      Successfully uninstalled ipykernel-5.2.0\n",
      "  Found existing installation: Jinja2 2.11.1\n",
      "    Uninstalling Jinja2-2.11.1:\n",
      "      Successfully uninstalled Jinja2-2.11.1\n",
      "  Found existing installation: json5 0.9.4\n",
      "    Uninstalling json5-0.9.4:\n",
      "      Successfully uninstalled json5-0.9.4\n",
      "  Found existing installation: nbformat 5.0.5\n",
      "    Uninstalling nbformat-5.0.5:\n",
      "      Successfully uninstalled nbformat-5.0.5\n",
      "  Found existing installation: notebook 6.0.3\n",
      "    Uninstalling notebook-6.0.3:\n",
      "      Successfully uninstalled notebook-6.0.3\n",
      "  Found existing installation: jupyterlab-server 1.0.7\n",
      "    Uninstalling jupyterlab-server-1.0.7:\n",
      "      Successfully uninstalled jupyterlab-server-1.0.7\n",
      "  Found existing installation: jupyterlab 2.0.1\n",
      "    Uninstalling jupyterlab-2.0.1:\n",
      "      Successfully uninstalled jupyterlab-2.0.1\n",
      "  Found existing installation: pyrsistent 0.16.0\n",
      "    Uninstalling pyrsistent-0.16.0:\n",
      "      Successfully uninstalled pyrsistent-0.16.0\n",
      "Successfully installed Jinja2-2.10.3 Pygments-2.5.2 Shapely-1.6.4.post2 Wand-0.5.8 beautifulsoup4-4.8.2 bleach-3.1.0 bs4-0.0.1 decorator-4.4.1 geomdl-5.2.9 importlib-metadata-1.4.0 ipykernel-5.1.3 ipython-7.11.1 jedi-0.15.2 json5-0.8.5 jupyter-client-5.3.4 jupyter-core-4.6.1 jupyterlab-1.2.5 jupyterlab-server-1.0.6 lxml-4.4.2 more-itertools-8.1.0 nbformat-5.0.3 nbstripout-0.3.7 networkx-2.4 notebook-6.0.2 numpy-1.18.1 parso-0.5.2 pexpect-4.7.0 prompt-toolkit-3.0.2 pyparsing-2.4.6 pyrsistent-0.15.7 pyzmq-18.1.1 soupsieve-1.9.5 svgwrite-1.3.1 tornado-6.0.3 wcwidth-0.1.8 zipp-1.0.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Enter the input file name\n",
    "\n",
    "input_file_name = '504b_The Voyage of the Dawn Treader - C. S. Lewis - complete.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: Generate output file names\n",
    "\n",
    "output_root = input_file_name[:-4]\n",
    "\n",
    "complete_output_file_name = output_root +'-complete.gexf'\n",
    "syuzhet_output_file_name = output_root + '-syuzhet.gexf'\n",
    "topoi_output_file_name = output_root + '-topoi-only.gexf'\n",
    "topoi_with_time_output_file_name = output_root + '-topoi-with-time.gexf'\n",
    "chronotope_output_file_name = output_root + '-frames-and-chronotopic-archetypes.gexf'\n",
    "chronotope_II_output_file_name = output_root + '-deep-chronotopes.gexf'\n",
    "chronotope_III_output_file_name = output_root + '-chronotopic-archetypes-and-toporefs.gexf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3: Import libraries\n",
    "\n",
    "from lxml import etree\n",
    "import networkx as nx\n",
    "\n",
    "from bs4 import BeautifulSoup, element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronotopes = [\n",
    "    'anti-idyll',\n",
    "    'castle',\n",
    "    'distortion',\n",
    "    'encounter',\n",
    "    'idyll',\n",
    "    'metanarrative',\n",
    "    'parlour',\n",
    "    'public square',\n",
    "    'road',\n",
    "    'threshold',\n",
    "    'provincial town',\n",
    "    'wilderness'\n",
    "]\n",
    "\n",
    "connections = [\n",
    "    'direct',\n",
    "    'indirect',\n",
    "    'interrupt',\n",
    "    'jump',\n",
    "    'charshift',\n",
    "    'projection',\n",
    "    'metatextual',\n",
    "    'paratextual',\n",
    "    'intratextual',\n",
    "    'metaphor'\n",
    "]\n",
    "        \n",
    "\n",
    "import pprint\n",
    "        \n",
    "def check_xml(xml_element):\n",
    "    \"\"\"\n",
    "    Checks for the most common problems with a Chrono-Carto-encoded XML file. \n",
    "    WARNING: this doesn't pick up inconsistencies in the naming of topoi, source and target tags\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    errors = {'nodes': [], 'connections': [], 'toporefs': []}\n",
    "    \n",
    "    warnings = {'nodes': [], 'connections': [], 'toporefs': []}\n",
    "    \n",
    "    sources_and_targets = {'sources': [], 'targets': []}\n",
    "    \n",
    "    nodes = []\n",
    "    \n",
    "    for topos in xml_element.iter('topos'):\n",
    "        try:\n",
    "            topos.attrib['type']\n",
    "            if topos.attrib['type'] not in chronotopes:\n",
    "                warnings['nodes'].append(['Check node type attribute on line ' + str(topos.sourceline), topos.attrib])\n",
    "        except:\n",
    "            errors['nodes'].append(['No type attribute on line ' + str(topos.sourceline), topos.attrib])\n",
    "        try:\n",
    "            topos.attrib['framename']\n",
    "            nodes.append(topos.attrib['framename'])\n",
    "        except:\n",
    "            errors['nodes'].append(['No framename attribute on line ' + str(topos.sourceline), topos.attrib])\n",
    "\n",
    "            \n",
    "    for connection in xml_element.iter('connection'):\n",
    "        try:\n",
    "            connection.attrib['source']\n",
    "        except:\n",
    "            errors['connections'].append(['No source attribute on line ' + str(connection.sourceline), connection.attrib])\n",
    "        try:\n",
    "            connection.attrib['target']\n",
    "        except:\n",
    "            errors['connections'].append(['No target attribute on line ' + str(connection.sourceline), connection.attrib])\n",
    "        try:\n",
    "            connection.attrib['relation']\n",
    "            if connection.attrib['relation'] not in connections:\n",
    "                warnings['connections'].append(['Check relation attribute on line ' + str(connection.sourceline), connection.attrib])\n",
    "        except:\n",
    "            errors['connections'].append(['No relation attribute on line ' + str(connection.sourceline), connection.attrib])\n",
    "\n",
    "            \n",
    "    for connection in xml_element.iter('connection'):\n",
    "        try:\n",
    "            if connection.attrib['source'] not in nodes:\n",
    "                sources_and_targets['sources'].append(['No matching topos for source attribute \"' + connection.attrib['source'] + '\" on line ' + str(connection.sourceline), connection.attrib])\n",
    "            if connection.attrib['target'] not in nodes:\n",
    "                sources_and_targets['targets'].append(['No matching topos for target attribute \"' + connection.attrib['target'] + '\" on line ' + str(connection.sourceline), connection.attrib])\n",
    "        except:\n",
    "            print(connection.sourceline, connection.attrib)\n",
    "    \n",
    "    \n",
    "    for toporef in xml_element.iter('toporef'):\n",
    "        try:\n",
    "            toporef.attrib['role']\n",
    "        except:\n",
    "            errors['toporefs'].append(['No role attribute on line ' + str(toporef.sourceline), toporef.attrib])\n",
    "        try:\n",
    "            toporef.attrib['relation']\n",
    "            if toporef.attrib['relation'] not in connections:\n",
    "                warnings['toporefs'].append(['Check relation attribute on line ' + str(toporef.sourceline), toporef.attrib])\n",
    "        except:\n",
    "            errors['toporefs'].append(['No relation attribute on line ' + str(toporef.sourceline), toporef.attrib])\n",
    "    \n",
    "    print('Errors:')\n",
    "    if (len(errors['connections']) > 0) or (len(errors['nodes']) > 0) or (len(errors['toporefs']) > 0):\n",
    "        pprint.pprint(errors)\n",
    "    else:\n",
    "        print('No errors found!')\n",
    "    print('')\n",
    "    print('Attribute typos:')\n",
    "    if (len(warnings['connections']) > 0) or (len(warnings['nodes']) > 0) or (len(warnings['toporefs']) > 0):\n",
    "        pprint.pprint(warnings)\n",
    "    else:\n",
    "        print('No attribute typos found!')\n",
    "    print('')\n",
    "    print('Source and Target mis-matches')\n",
    "    if (len(sources_and_targets['sources']) > 0) or (len(sources_and_targets['targets']) > 0):\n",
    "        pprint.pprint(sources_and_targets)\n",
    "    else:\n",
    "        print('No mismatches found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4: Read the XML file and create empty graph objects\n",
    "tree = etree.parse('files/xml/' + input_file_name)\n",
    "root = tree.getroot()\n",
    "complete = nx.DiGraph()\n",
    "syuzhet = nx.DiGraph()\n",
    "topoi = nx.DiGraph()\n",
    "chronotope = nx.Graph()\n",
    "chronotope_ii = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors:\n",
      "No errors found!\n",
      "\n",
      "Attribute typos:\n",
      "No attribute typos found!\n",
      "\n",
      "Source and Target mis-matches\n",
      "No mismatches found!\n"
     ]
    }
   ],
   "source": [
    "check_xml(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5: Define the functions for creating the graphs\n",
    "\n",
    "def complete_graph(xml_element, graph):\n",
    "    \"\"\"\n",
    "    Takes an XML element marked up using CLAYE and returns a populated graph of the spatial nodes, \n",
    "    litonyms, and the implied physical, psychological, or sensory connections between them. \n",
    "    \n",
    "    Params:\n",
    "    xml_element: an lxml XML element\n",
    "    graph: a NetworkX Graph() object - nx.Graph()\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add all the litonyms and topoi as nodes and connections as edges first\n",
    "    for toporef in xml_element.iter('toporef'):\n",
    "        graph.add_node('\"' + toporef.text + '\"', node_type='toporef')\n",
    "    \n",
    "    topos_count = 0\n",
    "    \n",
    "    for topos in xml_element.iter('topos'):\n",
    "        topos_count_str = str(topos_count)\n",
    "        try:\n",
    "            print(topos.attrib)\n",
    "            framename = topos.attrib['framename']\n",
    "            new_length = graph.nodes[framename]['length'] + len(''.join(topos.itertext()).strip())\n",
    "            graph.nodes[framename]['length'] = new_length\n",
    "            graph.nodes[framename]['timeframes'] = graph.nodes[framename]['timeframes'] + ',' + topos_count_str\n",
    "            \n",
    "        except KeyError:\n",
    "            graph.add_node(topos.attrib['framename'], length=len(''.join(topos.itertext()).strip()), chronotope=topos.attrib['type'], node_type=\"topos\", timeframes=topos_count_str)\n",
    "\n",
    "        topos_count += 1\n",
    "    \n",
    "    for connection in xml_element.iter('connection'):\n",
    "        try:\n",
    "            graph.add_edge(connection.attrib['source'], connection.attrib['target'], relation=connection.attrib['relation'])\n",
    "        except:\n",
    "            graph.add_edge(connection.attrib['source'], connection.attrib['target'], relation='none')\n",
    "    \n",
    "    # Connect the toporefs to the containing topoi\n",
    "    for toporef in xml_element.iter('toporef'):\n",
    "        if ('sequence' in toporef.attrib.keys()):\n",
    "            pass\n",
    "        else:\n",
    "            parent = toporef.getparent()\n",
    "            containing_node = None\n",
    "            if parent.tag == 'topos':\n",
    "                containing_node = parent.attrib['framename']\n",
    "            elif parent.tag == 'connection':\n",
    "                containing_topos = parent.getparent()\n",
    "                try:\n",
    "                    containing_node = containing_topos.attrib['framename']\n",
    "                except:\n",
    "                    pass\n",
    "            try:\n",
    "                graph.add_edge(containing_node, '\"' + toporef.text + '\"', relation=toporef.attrib['relation'])\n",
    "            except:\n",
    "                graph.add_edge(containing_node, '\"' + toporef.text + '\"', relation='none')\n",
    "    \n",
    "    # Connect the toporef sequences to one another\n",
    "    sequences = {}\n",
    "    for toporef in xml_element.iter('toporef'):\n",
    "        try:\n",
    "            sequence = toporef.attrib['sequence']\n",
    "            sequences[sequence] = []\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    for sequence in sequences.keys():\n",
    "        for toporef in xml_element.iter('toporef'):\n",
    "            try:\n",
    "                sequence = toporef.attrib['sequence']\n",
    "                sequences[sequence].append(toporef)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    for sequence, toporef_list in sequences.items():\n",
    "        prev_toporef = None\n",
    "        \n",
    "        for toporef in toporef_list:    \n",
    "            if prev_toporef == None:\n",
    "                parent = toporef.getparent()\n",
    "                containing_node = None\n",
    "                if parent.tag == 'topos':\n",
    "                    containing_node = parent.attrib['framename']\n",
    "                elif parent.tag == 'connection':\n",
    "                    containing_topos = parent.getparent()\n",
    "                    try:\n",
    "                        containing_node = containing_topos.attrib['framename']\n",
    "                    except:\n",
    "                        pass\n",
    "                try:\n",
    "                    graph.add_edge(containing_node, '\"' + toporef.text + '\"', relation=toporef.attrib['relation'])\n",
    "                except:\n",
    "                    graph.add_edge(containing_node, '\"' + toporef.text + '\"', relation='none')\n",
    "                \n",
    "                prev_toporef = toporef\n",
    "                    \n",
    "            else:\n",
    "                graph.add_edge('\"' + prev_toporef.text + '\"', '\"' + toporef.text + '\"', relation=toporef.attrib['relation'])\n",
    "                prev_toporef = toporef\n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "def syuzhet_graph(xml_element, graph):\n",
    "    \"\"\"\n",
    "    Takes an XML element marked up using CLAYE and returns a populated graph of the spatial nodes\n",
    "    connected sequentially as they appear in the text\n",
    "    Corresponds (loosely) with the syuzhet or story order of the text.\n",
    "    \n",
    "    Params:\n",
    "    xml_element: an lxml XML element\n",
    "    graph: a NetworkX Graph() object - nx.Graph()\n",
    "\n",
    "    \"\"\"\n",
    "    topoi = []\n",
    "\n",
    "    for topos in xml_element.iter('topos'):\n",
    "        topoi.append([topos.attrib['framename'], topos.attrib['type'], len(''.join(topos.itertext()).strip())])\n",
    "\n",
    "    prev_node = None\n",
    "    \n",
    "    for t in topoi:\n",
    "        if prev_node == None:\n",
    "            prev_node = t[0]\n",
    "            graph.add_node(t[0], chronotope=t[1], length=t[2])\n",
    "        else:\n",
    "            try:\n",
    "                graph.nodes[t[0]]['length'] += t[2]\n",
    "            except KeyError:\n",
    "                graph.add_node(t[0], chronotope=t[1], length=t[2])\n",
    "            \n",
    "            connection = None\n",
    "            \n",
    "            for c in xml_element.iter('connection'):\n",
    "                if (c.attrib['source'] == prev_node) and (c.attrib['target'] == t[0]):\n",
    "                    graph.add_edge(prev_node, t[0], relation=c.attrib['relation'])\n",
    "                    connection = [prev_node, t[0], c.attrib['relation']]\n",
    "                    print(c.attrib)\n",
    "                else:\n",
    "                    #graph.add_edge(prev_node, t[0], relation='none')\n",
    "                    connection = [prev_node, t[0], 'none']\n",
    "            \n",
    "            prev_node = t[0]\n",
    "\n",
    "            \n",
    "def topoi_graph(xml_element, graph):\n",
    "    \"\"\"\n",
    "    Iterate over an XML element and its children and generate a graph of topoi nodes and connections, including attributes.\n",
    "    xml_element: an eTree XML element\n",
    "    graph: a NetworkX Graph() object - nx.Graph()\n",
    "    \"\"\"\n",
    "    \n",
    "    for topos in xml_element.iter('topos'):\n",
    "        try:\n",
    "            graph.nodes[topos.attrib['framename']]['length'] += len(''.join(topos.itertext()).strip())\n",
    "        except KeyError:\n",
    "            graph.add_node(topos.attrib['framename'], chronotope=topos.attrib['type'], length=len(''.join(topos.itertext()).strip()))\n",
    "\n",
    "    for c in xml_element.iter('connection'):\n",
    "        try:\n",
    "            graph.add_edge(c.attrib['source'], c.attrib['target'], relation=c.attrib['relation'])\n",
    "        except KeyError:\n",
    "            print(c.attrib)\n",
    "            \n",
    "\n",
    "def topoi_graph_with_time(xml_element, graph):\n",
    "    \"\"\"\n",
    "    Iterate over an XML element and its children and generate a graph of topoi nodes and connections, including attributes.\n",
    "    xml_element: an eTree XML element\n",
    "    graph: a NetworkX Graph() object - nx.Graph()\n",
    "    \"\"\"\n",
    "    \n",
    "    topos_count = 0\n",
    "    \n",
    "    for topos in xml_element.iter('topos'):\n",
    "        topos_count_string = str(topos_count)\n",
    "        try:\n",
    "            graph.nodes[topos.attrib['framename']]['length'] += len(''.join(topos.itertext()).strip())\n",
    "            timeframes = graph.nodes[topos.attrib['framename']]['timeframes'] + ',' + topos_count_string \n",
    "            graph.nodes[topos.attrib['framename']]['timeframes'] = timeframes\n",
    "        except KeyError:\n",
    "            graph.add_node(topos.attrib['framename'], chronotope=topos.attrib['type'], length=len(''.join(topos.itertext()).strip()), timeframes=topos_count_string)\n",
    "            \n",
    "        topos_count += 1\n",
    "    \n",
    "\n",
    "    for c in xml_element.iter('connection'):\n",
    "        try:\n",
    "            graph.add_edge(c.attrib['source'], c.attrib['target'], relation=c.attrib['relation'])\n",
    "        except KeyError:\n",
    "            print(c.attrib)\n",
    "\n",
    "\n",
    "\n",
    "def chronotope_graph(xml_element, graph):\n",
    "    \"\"\"\n",
    "    Takes an XML element marked up using CLAYE and returns a populated graph of the topoi\n",
    "    and their associated chronotopes\n",
    "    \n",
    "    Params:\n",
    "    xml_element: an lxml XML element\n",
    "    graph: a NetworkX Graph() object - nx.Graph()\n",
    "    \"\"\"\n",
    "    \n",
    "    for topos in xml_element.iter('topos'):\n",
    "        graph.add_node(topos.attrib['type'], node_type='chronotope')\n",
    "        graph.add_node(topos.attrib['framename'], node_type='setting')\n",
    "        graph.add_edge(topos.attrib['type'], topos.attrib['framename'])\n",
    "\n",
    "\n",
    "def chronotope_graph_ii(soup, graph):\n",
    "    \n",
    "    # Add all the connections first\n",
    "    edges = []\n",
    "    for connection in soup.find_all('connection'):\n",
    "        source = connection.get('source')\n",
    "        target = connection.get('target')\n",
    "        relation = connection.get('relation')\n",
    "        \n",
    "        source_chronotope = None\n",
    "        target_chronotope = None\n",
    "        \n",
    "        if (connection.parent.get('framename') == source):\n",
    "            source_chronotope = connection.parent.get('type')\n",
    "        \n",
    "        else:\n",
    "            for el in connection.previous_elements:\n",
    "                if (isinstance(el, element.Tag) == True):\n",
    "                    if el.get('framename') == source and source_chronotope is None:\n",
    "                        source_chronotope = el.get('type')\n",
    "                    elif el.get('framename') == target and target_chronotope is None:\n",
    "                        target_chronotope = el.get('type')\n",
    "        \n",
    "        for el in connection.next_elements:\n",
    "            if (isinstance(el, element.Tag) == True and el.get('type') is not None):\n",
    "                if el.get('framename') == target and target_chronotope is None:\n",
    "                    target_chronotope = el.get('type')\n",
    "                elif el.get('framename') == source and source_chronotope is None:\n",
    "                    source_chronotope = el.get('type')\n",
    "        \n",
    "        if (source_chronotope != None and target_chronotope != None):\n",
    "            edges.append((source_chronotope, target_chronotope, relation))\n",
    "            \n",
    "    edges = list(set(edges))\n",
    "    \n",
    "    for e in edges:\n",
    "        graph.add_edge(e[0], e[1], relation=e[2])\n",
    "        \n",
    "    print(graph.nodes)\n",
    "    \n",
    "    # Then iterate over the topoi and calculate the number of characters in each, appending the values to the nodes\n",
    "    chronotopes = {}\n",
    "    for topos in soup.find_all('topos'):\n",
    "        chronotope = topos.get('type')\n",
    "        try:\n",
    "            if chronotope not in chronotopes.keys():\n",
    "                chronotopes[chronotope] = len(topos.get_text())\n",
    "            else:\n",
    "                chronotopes[chronotope] += len(topos.get_text())\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    for c, attribs in chronotopes.items():\n",
    "        print(c)\n",
    "        graph.nodes[c]['length'] = attribs    \n",
    "\n",
    "    \n",
    "def chronotope_graph_iii(xml_element, graph):\n",
    "    \"\"\"\n",
    "    Takes an XML element marked up using CLAYE and returns a populated graph of the chronotope archteypes, \n",
    "    their connections, and their associated toporefs\n",
    "    \n",
    "    \"\"\"\n",
    "    topoi = {}\n",
    "    for topos in xml_element.iter('topos'):\n",
    "        try: \n",
    "            chronotope = topos.attrib['type']\n",
    "            graph.nodes[chronotope]['length'] += len(''.join(topos.itertext()).strip())\n",
    "        except KeyError:\n",
    "            graph.add_node(topos.attrib['type'], length=len(''.join(topos.itertext()).strip()))\n",
    "        topoi[topos.attrib['framename']] = topos.attrib['type']\n",
    "    \n",
    "    for connection in xml_element.iter('connection'):\n",
    "        try:\n",
    "            source_chronotope = topoi[connection.attrib['source']]\n",
    "            target_chronotope = topoi[connection.attrib['target']]\n",
    "            relation = connection.attrib['relation']\n",
    "            graph.add_edge(source_chronotope, target_chronotope, relation=relation)\n",
    "        except:\n",
    "            print('error')\n",
    "    \n",
    "    for topos in xml_element.iter('topos'):\n",
    "        try:\n",
    "            chronotope = topos.attrib['type']\n",
    "            for toporef in topos.iter('toporef'):\n",
    "                graph.add_edge(chronotope, '\"' + toporef.text + '\"', relation=toporef.attrib['relation'])\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "topoi_cc_over_time = nx.DiGraph()\n",
    "\n",
    "def topoi_with_chronotopes_and_connections_over_time(xml_element, graph):\n",
    "    \"\"\"\n",
    "    Takes an XML element and sequentially builds a populated graph of topoi, recording the temporal index, size, and chronotope \n",
    "    of each as they are encountered, and the temporal index of the connecting edges.\n",
    "    \"\"\"\n",
    "    topoi = {}\n",
    "    connections = []\n",
    "    index = 0\n",
    "    \n",
    "    for el in xml_element.iter():\n",
    "        if el.tag == 'topos':\n",
    "            if el.attrib['framename'] not in topoi.keys():\n",
    "                topoi[el.attrib['framename']] = {}\n",
    "                topoi[el.attrib['framename']]['chronotopes'] = [el.attrib['type']]\n",
    "                topoi[el.attrib['framename']]['time_indices'] = [str(index)]\n",
    "                topoi[el.attrib['framename']]['text_lengths'] = [str(len(el.text))]\n",
    "            else:\n",
    "                topoi[el.attrib['framename']]['chronotopes'].append(el.attrib['type'])\n",
    "                topoi[el.attrib['framename']]['time_indices'].append(str(index))\n",
    "                topoi[el.attrib['framename']]['text_lengths'].append(str(len(el.text)))\n",
    "                \n",
    "            \n",
    "            \n",
    "        if el.tag == 'connection':\n",
    "            connection = {}\n",
    "            connection['source'] = el.attrib['source']\n",
    "            connection['target'] = el.attrib['target']\n",
    "            connection['relation'] = el.attrib['relation']\n",
    "            connection['source_index'] = index \n",
    "            connection['target_index'] = index +1\n",
    "            connections.append(connection)\n",
    "            \n",
    "            index = index +1\n",
    "    \n",
    "    for node, attributes in topoi.items():\n",
    "        chronotopes = ', '.join(attributes['chronotopes'])\n",
    "        indices = ', '.join(attributes['time_indices'])\n",
    "        text_lengths = ', '.join(attributes['text_lengths'])\n",
    "        graph.add_node(node, chronotopes=chronotopes, time_indices=indices, text_lengths=text_lengths)\n",
    "    \n",
    "    for edge in connections:\n",
    "        graph.add_edge(edge['source'], edge['target'], source_index=edge['source_index'], target_index=edge['target_index'], relation=edge['relation'])   \n",
    "\n",
    "        \n",
    "topoi_with_chronotopes_and_connections_over_time(root, topoi_cc_over_time)\n",
    "\n",
    "with open('files/graphs/pw_topoi_with_time.gexf', 'w') as output_file:\n",
    "    for line in nx.readwrite.gexf.generate_gexf(topoi_cc_over_time):\n",
    "        output_file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors:\n",
      "No errors found!\n",
      "\n",
      "Attribute typos:\n",
      "No attribute typos found!\n",
      "\n",
      "Source and Target mis-matches\n",
      "No mismatches found!\n"
     ]
    }
   ],
   "source": [
    "check_xml(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'metanarrative', 'framename': 'Preamble - Eustace Clarence Scrubb'}\n",
      "{'type': 'threshold', 'framename': \"The Scrubb's - Lucy's Room\"}\n",
      "{'framename': 'The Children Fall into the Sea', 'type': 'wilderness'}\n",
      "{'framename': 'The Dawn Treader - Main Deck', 'type': 'public square'}\n",
      "{'type': 'parlour', 'framename': 'The Dawn Treader - Stern Cabin'}\n",
      "{'framename': 'The Dawn Treader - Main Deck', 'type': 'public square'}\n",
      "{'framename': 'The Dawn Treader - Lower Deck', 'type': 'public square'}\n",
      "{'framename': 'The Dawn Treader - Lower Deck Cabin', 'type': 'parlour'}\n",
      "{'type': 'public square', 'framename': 'The Dawn Treader - Forecastle'}\n",
      "{'type': 'castle', 'framename': 'The Dawn Treader - Fighting Top'}\n",
      "{'type': 'public square', 'framename': 'The Dawn Treader - Poop Deck'}\n",
      "{'type': 'parlour', 'framename': 'The Dawn Treader - Stern Cabin'}\n",
      "{'framename': \"Eustace's Diary\", 'type': 'metanarrative'}\n",
      "{'framename': 'The Dawn Treader - Stern Cabin', 'type': 'parlour'}\n",
      "{'framename': 'The Dawn Treader - Forecastle', 'type': 'public square'}\n",
      "{'framename': 'The Dawn Treader - Stern Cabin', 'type': 'parlour'}\n",
      "{'framename': 'The Dawn Treader - Lower Deck Cabin', 'type': 'castle'}\n",
      "{'framename': 'The Dawn Treader - Forecastle', 'type': 'public square'}\n",
      "{'framename': 'Felimath - Beach', 'type': 'wilderness'}\n",
      "{'framename': 'Felimath - Valley', 'type': 'encounter'}\n",
      "{'framename': 'Felimath - Village', 'type': 'provincial town'}\n",
      "{'framename': 'Slave Ship', 'type': 'castle'}\n",
      "{'framename': 'Felimath - Behind the Village', 'type': 'provincial town'}\n",
      "{'framename': 'Felimath - West of the Village', 'type': 'provincial town'}\n",
      "{'framename': \"Avra - Bern's Estates\", 'type': 'idyll'}\n",
      "{'framename': 'Doorn - Narrowhaven', 'type': 'provincial town'}\n",
      "{'framename': 'Doorn - Narrowhaven Castle Gate', 'type': 'threshold'}\n",
      "{'framename': 'Doorn - Narrowhaven Castle Courtyard', 'type': 'castle'}\n",
      "{'framename': 'Doorn - Narrowhaven Castle Hall', 'type': 'public square'}\n",
      "{'framename': 'Doorn - Narrowhaven Slave Market', 'type': 'public square'}\n",
      "{'framename': 'Doorn - Narrowhaven', 'type': 'provincial town'}\n",
      "{'framename': \"Avra - Bern's Estates\", 'type': 'idyll'}\n",
      "{'framename': 'Doorn - Narrowhaven Harbour', 'type': 'threshold'}\n",
      "{'framename': 'The Dawn Treader - Forecastle', 'type': 'public square'}\n",
      "{'framename': 'The Dawn Treader - Stern Cabin', 'type': 'parlour'}\n",
      "{'framename': 'The Dawn Treader - Poop Deck', 'type': 'castle'}\n",
      "{'framename': 'The Dawn Treader - Stern Cabin', 'type': 'castle'}\n",
      "{'framename': 'The Dawn Treader', 'type': 'castle'}\n",
      "{'framename': \"Eustace's Diary\", 'type': 'metanarrative'}\n",
      "{'framename': 'Dragon Island - Bay', 'type': 'wilderness'}\n",
      "{'framename': 'Dragon Island - Woods', 'type': 'wilderness'}\n",
      "{'framename': 'Dragon Island - Ridge', 'type': 'wilderness'}\n",
      "{'framename': 'Dragon Island - Valley', 'type': 'castle'}\n",
      "{'framename': 'Dragon Island - Cave', 'type': 'castle'}\n",
      "{'framename': 'Dragon Island - Bay', 'type': 'public square'}\n",
      "{'framename': 'Dragon Island - Cave', 'type': 'castle'}\n",
      "{'framename': 'Dragon Island - Valley', 'type': 'castle'}\n",
      "{'framename': 'Dragon Island - Bay', 'type': 'public square'}\n",
      "{'framename': \"Dragon Island - The Garden of Eustace's Transformation\", 'type': 'encounter'}\n",
      "{'framename': 'Dragon Island - Bay', 'type': 'public square'}\n",
      "{'framename': 'Burnt Island', 'type': 'anti-idyll'}\n",
      "{'framename': 'The Dawn Treader - Stern Cabin', 'type': 'parlour'}\n",
      "{'framename': 'The Dawn Treader - Poop Deck', 'type': 'public square'}\n",
      "{'framename': 'Deathwater Island - Bay', 'type': 'wilderness'}\n",
      "{'framename': 'Deathwater Island - Hill', 'type': 'wilderness'}\n",
      "{'framename': 'Deathwater Island - Lake', 'type': 'anti-idyll'}\n",
      "{'framename': 'The Dawn Treader', 'type': 'public square'}\n",
      "{'framename': \"Coriakin's Island - Gardens\", 'type': 'provincial town'}\n",
      "{'framename': \"Coriakin's Island - Path\", 'type': 'encounter'}\n",
      "{'framename': \"Coriakin's Island - Outside the House\", 'type': 'threshold'}\n",
      "{'framename': \"Coriakin's Island - Beach\", 'type': 'encounter'}\n",
      "{'framename': \"Coriakin's Island - Hall\", 'type': 'parlour'}\n",
      "{'framename': \"Coriakin's Island - Lucy's Bedroom\", 'type': 'parlour'}\n",
      "{'framename': \"Coriakin's Island - Hall\", 'type': 'public square'}\n",
      "{'framename': \"Coriakin's Island - Stairs\", 'type': 'castle'}\n",
      "{'framename': \"Coriakin's Island - Passageway\", 'type': 'castle'}\n",
      "{'framename': \"Coriakin's Island - Room of the Book\", 'type': 'parlour'}\n",
      "{'framename': \"Coriakin's Island - Passageway\", 'type': 'parlour'}\n",
      "{'framename': \"Coriakin's Island - Parlour\", 'type': 'parlour'}\n",
      "{'framename': \"Coriakin's Island - Room of Instruments\", 'type': 'parlour'}\n",
      "{'framename': \"Coriakin's Island - Stairs\", 'type': 'parlour'}\n",
      "{'framename': \"Coriakin's Island - Gardens\", 'type': 'idyll'}\n",
      "{'framename': \"Coriakin's Island - Bay\", 'type': 'idyll'}\n",
      "{'framename': \"Coriakin's Island - Hall\", 'type': 'public square'}\n",
      "{'framename': \"Coriakin's Island - Bay\", 'type': 'idyll'}\n",
      "{'framename': 'The Dawn Treader', 'type': 'public square'}\n",
      "{'framename': 'The Dawn Treader - Main Deck', 'type': 'anti-idyll'}\n",
      "{'framename': 'The Dawn Treader - Fighting Top', 'type': 'castle'}\n",
      "{'framename': 'The Dawn Treader - The Bows', 'type': 'castle'}\n",
      "{'framename': 'The Dawn Treader - Main Deck', 'type': 'anti-idyll'}\n",
      "{'framename': 'The Dawn Treader - Fighting Top', 'type': 'castle'}\n",
      "{'framename': 'The Dawn Treader - Near the Dark Island', 'type': 'anti-idyll'}\n",
      "{'framename': 'The Dawn Treader - Main Deck', 'type': 'public square'}\n",
      "{'framename': 'The Dawn Treader', 'type': 'public square'}\n",
      "{'framename': \"Ramandu's Island - Bay\", 'type': 'wilderness'}\n",
      "{'framename': \"Ramandu's Island - Aslan's Table\", 'type': 'castle'}\n",
      "{'framename': 'The Dawn Treader', 'type': 'public square'}\n",
      "{'framename': 'The Dawn Treader - Main Deck', 'type': 'public square'}\n",
      "{'framename': 'The Dawn Treader - Above the Sea People', 'type': 'encounter'}\n",
      "{'framename': 'The Dawn Treader - Main Deck', 'type': 'public square'}\n",
      "{'framename': 'The Dawn Treader - Eastern Sea', 'type': 'idyll'}\n",
      "{'framename': 'The Dawn Treader - Silver Sea', 'type': 'idyll'}\n",
      "{'framename': 'The Dawn Treader - Main Deck', 'type': 'public square'}\n",
      "{'framename': 'The Dawn Treader - Lower Deck Cabin', 'type': 'parlour'}\n",
      "{'framename': 'The Dawn Treader - Main Deck', 'type': 'public square'}\n",
      "{'framename': 'Boat - Towards the Edge of the World', 'type': 'road'}\n",
      "{'framename': 'The Edge of the World', 'type': 'idyll'}\n",
      "{'framename': 'The Lion and the Lamb', 'type': 'idyll'}\n",
      "{'framename': \"The Scrubb's - Lucy's Room\", 'type': 'parlour'}\n",
      "{'framename': 'Postscript', 'type': 'metanarrative'}\n"
     ]
    }
   ],
   "source": [
    "# 6: Complete\n",
    "\n",
    "complete = nx.DiGraph()\n",
    "\n",
    "complete_graph(root, complete)\n",
    "\n",
    "with open('files/graphs/' + complete_output_file_name, 'w') as output_file:\n",
    "    for line in nx.readwrite.gexf.generate_gexf(complete):\n",
    "        output_file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'Preamble - Eustace Clarence Scrubb', 'target': \"The Scrubb's - Lucy's Room\", 'relation': 'direct'}\n",
      "{'source': \"The Scrubb's - Lucy's Room\", 'target': 'The Children Fall into the Sea', 'relation': 'direct'}\n",
      "{'source': 'The Children Fall into the Sea', 'target': 'The Dawn Treader - Main Deck', 'relation': 'direct'}\n",
      "{'source': 'The Dawn Treader - Main Deck', 'target': 'The Dawn Treader - Stern Cabin', 'relation': 'direct'}\n",
      "{'source': 'The Dawn Treader - Stern Cabin', 'target': 'The Dawn Treader - Main Deck', 'relation': 'direct'}\n",
      "{'source': 'The Dawn Treader - Main Deck', 'target': 'The Dawn Treader - Lower Deck', 'relation': 'direct'}\n",
      "{'source': 'The Dawn Treader - Lower Deck', 'target': 'The Dawn Treader - Lower Deck Cabin', 'relation': 'direct'}\n",
      "{'source': 'The Dawn Treader - Lower Deck Cabin', 'target': 'The Dawn Treader - Forecastle', 'relation': 'direct'}\n",
      "{'source': 'The Dawn Treader - Lower Deck Cabin', 'target': 'The Dawn Treader - Forecastle', 'relation': 'jump'}\n",
      "{'source': 'The Dawn Treader - Forecastle', 'target': 'The Dawn Treader - Fighting Top', 'relation': 'direct'}\n",
      "{'source': 'The Dawn Treader - Fighting Top', 'target': 'The Dawn Treader - Poop Deck', 'relation': 'direct'}\n",
      "{'source': 'The Dawn Treader - Poop Deck', 'target': 'The Dawn Treader - Stern Cabin', 'relation': 'direct'}\n",
      "{'source': 'The Dawn Treader - Poop Deck', 'target': 'The Dawn Treader - Stern Cabin', 'relation': 'direct'}\n",
      "{'source': 'The Dawn Treader - Stern Cabin', 'target': \"Eustace's Diary\", 'relation': 'jump'}\n",
      "{'source': \"Eustace's Diary\", 'target': 'The Dawn Treader - Stern Cabin', 'relation': 'jump'}\n",
      "{'source': 'The Dawn Treader - Stern Cabin', 'target': 'The Dawn Treader - Forecastle', 'relation': 'jump'}\n",
      "{'source': 'The Dawn Treader - Forecastle', 'target': 'The Dawn Treader - Stern Cabin', 'relation': 'jump'}\n",
      "{'source': 'The Dawn Treader - Forecastle', 'target': 'The Dawn Treader - Stern Cabin', 'relation': 'jump'}\n",
      "{'source': 'The Dawn Treader - Stern Cabin', 'target': 'The Dawn Treader - Lower Deck Cabin', 'relation': 'direct'}\n",
      "{'source': 'The Dawn Treader - Lower Deck Cabin', 'target': 'The Dawn Treader - Forecastle', 'relation': 'direct'}\n",
      "{'source': 'The Dawn Treader - Lower Deck Cabin', 'target': 'The Dawn Treader - Forecastle', 'relation': 'jump'}\n",
      "{'source': 'The Dawn Treader - Forecastle', 'target': 'Felimath - Beach', 'relation': 'direct'}\n",
      "{'source': 'Felimath - Beach', 'target': 'Felimath - Valley', 'relation': 'direct'}\n",
      "{'source': 'Felimath - Valley', 'target': 'Felimath - Village', 'relation': 'direct'}\n",
      "{'source': 'Felimath - Village', 'target': 'Slave Ship', 'relation': 'direct'}\n",
      "{'source': 'Slave Ship', 'target': 'Felimath - Behind the Village', 'relation': 'jump'}\n",
      "{'source': 'Felimath - Behind the Village', 'target': 'Felimath - West of the Village', 'relation': 'direct'}\n",
      "{'source': 'Felimath - West of the Village', 'target': \"Avra - Bern's Estates\", 'relation': 'direct'}\n",
      "{'source': \"Avra - Bern's Estates\", 'target': 'Doorn - Narrowhaven', 'relation': 'direct'}\n",
      "{'source': 'Doorn - Narrowhaven', 'target': 'Doorn - Narrowhaven Castle Gate', 'relation': 'direct'}\n",
      "{'source': 'Doorn - Narrowhaven Castle Gate', 'target': 'Doorn - Narrowhaven Castle Courtyard', 'relation': 'direct'}\n",
      "{'source': 'Doorn - Narrowhaven Castle Courtyard', 'target': 'Doorn - Narrowhaven Castle Hall', 'relation': 'direct'}\n",
      "{'source': 'Doorn - Narrowhaven Castle Hall', 'target': 'Doorn - Narrowhaven Slave Market', 'relation': 'direct'}\n",
      "{'source': 'Doorn - Narrowhaven Slave Market', 'target': 'Doorn - Narrowhaven', 'relation': 'jump'}\n",
      "{'source': 'Doorn - Narrowhaven', 'target': \"Avra - Bern's Estates\", 'relation': 'jump'}\n",
      "{'source': \"Avra - Bern's Estates\", 'target': 'Doorn - Narrowhaven Harbour', 'relation': 'jump'}\n",
      "{'source': 'Doorn - Narrowhaven Harbour', 'target': 'The Dawn Treader - Forecastle', 'relation': 'jump'}\n",
      "{'source': 'The Dawn Treader - Forecastle', 'target': 'The Dawn Treader - Stern Cabin', 'relation': 'jump'}\n",
      "{'source': 'The Dawn Treader - Forecastle', 'target': 'The Dawn Treader - Stern Cabin', 'relation': 'jump'}\n",
      "{'source': 'The Dawn Treader - Stern Cabin', 'target': 'The Dawn Treader - Poop Deck', 'relation': 'jump'}\n",
      "{'source': 'The Dawn Treader - Stern Cabin', 'target': 'The Dawn Treader - Poop Deck', 'relation': 'direct'}\n",
      "{'source': 'The Dawn Treader - Poop Deck', 'target': 'The Dawn Treader - Stern Cabin', 'relation': 'direct'}\n",
      "{'source': 'The Dawn Treader - Poop Deck', 'target': 'The Dawn Treader - Stern Cabin', 'relation': 'direct'}\n",
      "{'source': 'The Dawn Treader - Stern Cabin', 'target': 'The Dawn Treader', 'relation': 'jump'}\n",
      "{'source': 'The Dawn Treader', 'target': \"Eustace's Diary\", 'relation': 'jump'}\n",
      "{'source': \"Eustace's Diary\", 'target': 'Dragon Island - Bay', 'relation': 'jump'}\n",
      "{'source': 'Dragon Island - Bay', 'target': 'Dragon Island - Woods', 'relation': 'direct'}\n",
      "{'source': 'Dragon Island - Woods', 'target': 'Dragon Island - Ridge', 'relation': 'direct'}\n",
      "{'source': 'Dragon Island - Ridge', 'target': 'Dragon Island - Valley', 'relation': 'direct'}\n",
      "{'source': 'Dragon Island - Valley', 'target': 'Dragon Island - Cave', 'relation': 'direct'}\n",
      "{'source': 'Dragon Island - Cave', 'target': 'Dragon Island - Bay', 'relation': 'jump'}\n",
      "{'source': 'Dragon Island - Bay', 'target': 'Dragon Island - Cave', 'relation': 'jump'}\n",
      "{'source': 'Dragon Island - Cave', 'target': 'Dragon Island - Valley', 'relation': 'direct'}\n",
      "{'source': 'Dragon Island - Valley', 'target': 'Dragon Island - Bay', 'relation': 'jump'}\n",
      "{'source': 'Dragon Island - Bay', 'target': \"Dragon Island - The Garden of Eustace's Transformation\", 'relation': 'direct'}\n",
      "{'source': \"Dragon Island - The Garden of Eustace's Transformation\", 'target': 'Dragon Island - Bay', 'relation': 'projection'}\n",
      "{'source': 'Dragon Island - Bay', 'target': 'Burnt Island', 'relation': 'direct'}\n",
      "{'source': 'Burnt Island', 'target': 'The Dawn Treader - Stern Cabin', 'relation': 'jump'}\n",
      "{'source': 'The Dawn Treader - Stern Cabin', 'target': 'The Dawn Treader - Poop Deck', 'relation': 'jump'}\n",
      "{'source': 'The Dawn Treader - Stern Cabin', 'target': 'The Dawn Treader - Poop Deck', 'relation': 'direct'}\n",
      "{'source': 'The Dawn Treader - Poop Deck', 'target': 'Deathwater Island - Bay', 'relation': 'jump'}\n",
      "{'source': 'Deathwater Island - Bay', 'target': 'Deathwater Island - Hill', 'relation': 'direct'}\n",
      "{'source': 'Deathwater Island - Hill', 'target': 'Deathwater Island - Lake', 'relation': 'direct'}\n",
      "{'source': 'Deathwater Island - Lake', 'target': 'The Dawn Treader', 'relation': 'direct'}\n",
      "{'source': 'The Dawn Treader', 'target': \"Coriakin's Island - Gardens\", 'relation': 'direct'}\n",
      "{'source': \"Coriakin's Island - Gardens\", 'target': \"Coriakin's Island - Path\", 'relation': 'direct'}\n",
      "{'source': \"Coriakin's Island - Path\", 'target': \"Coriakin's Island - Outside the House\", 'relation': 'jump'}\n",
      "{'source': \"Coriakin's Island - Outside the House\", 'target': \"Coriakin's Island - Beach\", 'relation': 'direct'}\n",
      "{'source': \"Coriakin's Island - Beach\", 'target': \"Coriakin's Island - Hall\", 'relation': 'direct'}\n",
      "{'source': \"Coriakin's Island - Hall\", 'target': \"Coriakin's Island - Lucy's Bedroom\", 'relation': 'jump'}\n",
      "{'source': \"Coriakin's Island - Lucy's Bedroom\", 'target': \"Coriakin's Island - Hall\", 'relation': 'jump'}\n",
      "{'source': \"Coriakin's Island - Hall\", 'target': \"Coriakin's Island - Stairs\", 'relation': 'jump'}\n",
      "{'source': \"Coriakin's Island - Stairs\", 'target': \"Coriakin's Island - Passageway\", 'relation': 'direct'}\n",
      "{'source': \"Coriakin's Island - Passageway\", 'target': \"Coriakin's Island - Room of the Book\", 'relation': 'direct'}\n",
      "{'source': \"Coriakin's Island - Room of the Book\", 'target': \"Coriakin's Island - Passageway\", 'relation': 'direct'}\n",
      "{'source': \"Coriakin's Island - Passageway\", 'target': \"Coriakin's Island - Parlour\", 'relation': 'direct'}\n",
      "{'source': \"Coriakin's Island - Parlour\", 'target': \"Coriakin's Island - Room of Instruments\", 'relation': 'direct'}\n",
      "{'source': \"Coriakin's Island - Room of Instruments\", 'target': \"Coriakin's Island - Stairs\", 'relation': 'direct'}\n",
      "{'source': \"Coriakin's Island - Stairs\", 'target': \"Coriakin's Island - Gardens\", 'relation': 'direct'}\n",
      "{'source': \"Coriakin's Island - Gardens\", 'target': \"Coriakin's Island - Bay\", 'relation': 'direct'}\n",
      "{'source': \"Coriakin's Island - Bay\", 'target': \"Coriakin's Island - Hall\", 'relation': 'jump'}\n",
      "{'source': \"Coriakin's Island - Hall\", 'target': \"Coriakin's Island - Bay\", 'relation': 'jump'}\n",
      "{'source': \"Coriakin's Island - Bay\", 'target': 'The Dawn Treader', 'relation': 'jump'}\n",
      "{'source': 'The Dawn Treader', 'target': 'The Dawn Treader - Main Deck', 'relation': 'direct'}\n",
      "{'source': 'The Dawn Treader', 'target': 'The Dawn Treader - Main Deck', 'relation': 'jump'}\n",
      "{'source': 'The Dawn Treader - Main Deck', 'target': 'The Dawn Treader - Fighting Top', 'relation': 'jump'}\n",
      "{'source': 'The Dawn Treader - Main Deck', 'target': 'The Dawn Treader - Fighting Top', 'relation': 'jump'}\n",
      "{'source': 'The Dawn Treader - Fighting Top', 'target': 'The Dawn Treader - The Bows', 'relation': 'jump'}\n",
      "{'source': 'The Dawn Treader - The Bows', 'target': 'The Dawn Treader - Main Deck', 'relation': 'jump'}\n",
      "{'source': 'The Dawn Treader - Main Deck', 'target': 'The Dawn Treader - Fighting Top', 'relation': 'jump'}\n",
      "{'source': 'The Dawn Treader - Main Deck', 'target': 'The Dawn Treader - Fighting Top', 'relation': 'jump'}\n",
      "{'source': 'The Dawn Treader - Fighting Top', 'target': 'The Dawn Treader - Near the Dark Island', 'relation': 'direct'}\n",
      "{'source': 'The Dawn Treader - Near the Dark Island', 'target': 'The Dawn Treader - Main Deck', 'relation': 'direct'}\n",
      "{'source': 'The Dawn Treader - Main Deck', 'target': 'The Dawn Treader', 'relation': 'jump'}\n",
      "{'source': 'The Dawn Treader - Main Deck', 'target': 'The Dawn Treader', 'relation': 'jump'}\n",
      "{'source': 'The Dawn Treader', 'target': \"Ramandu's Island - Bay\", 'relation': 'direct'}\n",
      "{'source': \"Ramandu's Island - Bay\", 'target': \"Ramandu's Island - Aslan's Table\", 'relation': 'direct'}\n",
      "{'source': \"Ramandu's Island - Aslan's Table\", 'target': 'The Dawn Treader', 'relation': 'jump'}\n",
      "{'source': 'The Dawn Treader', 'target': 'The Dawn Treader - Main Deck', 'relation': 'direct'}\n",
      "{'source': 'The Dawn Treader', 'target': 'The Dawn Treader - Main Deck', 'relation': 'jump'}\n",
      "{'source': 'The Dawn Treader - Main Deck', 'target': 'The Dawn Treader - Above the Sea People', 'relation': 'direct'}\n",
      "{'source': 'The Dawn Treader - Above the Sea People', 'target': 'The Dawn Treader - Main Deck', 'relation': 'direct'}\n",
      "{'source': 'The Dawn Treader - Eastern Sea', 'target': 'The Dawn Treader - Silver Sea', 'relation': 'direct'}\n",
      "{'source': 'The Dawn Treader - Silver Sea', 'target': 'The Dawn Treader - Main Deck', 'relation': 'jump'}\n",
      "{'source': 'The Dawn Treader - Main Deck', 'target': 'The Dawn Treader - Lower Deck Cabin', 'relation': 'direct'}\n",
      "{'source': 'The Dawn Treader - Lower Deck Cabin', 'target': 'The Dawn Treader - Main Deck', 'relation': 'jump'}\n",
      "{'source': 'The Dawn Treader - Main Deck', 'target': 'Boat - Towards the Edge of the World', 'relation': 'direct'}\n",
      "{'source': 'Boat - Towards the Edge of the World', 'target': 'The Edge of the World', 'relation': 'direct'}\n",
      "{'source': 'The Edge of the World', 'target': 'The Lion and the Lamb', 'relation': 'direct'}\n",
      "{'source': 'The Lion and the Lamb', 'target': \"The Scrubb's - Lucy's Room\", 'relation': 'direct'}\n",
      "{'source': \"The Scrubb's - Lucy's Room\", 'target': 'Postscript', 'relation': 'jump'}\n"
     ]
    }
   ],
   "source": [
    "# 7: Syujhet\n",
    "\n",
    "syuzhet_graph(root, syuzhet)\n",
    "\n",
    "with open('files/graphs/' + syuzhet_output_file_name, 'w') as output_file:\n",
    "    for line in nx.readwrite.gexf.generate_gexf(syuzhet):\n",
    "        output_file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8: Topoi\n",
    "\n",
    "topoi_graph(root, topoi)\n",
    "\n",
    "with open('files/graphs/' + topoi_output_file_name, 'w') as output_file:\n",
    "    for line in nx.readwrite.gexf.generate_gexf(topoi):\n",
    "        output_file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = nx.DiGraph()\n",
    "\n",
    "topoi_graph_with_time(root, tt)\n",
    "\n",
    "with open('files/graphs/' + topoi_with_time_output_file_name, 'w') as output_file:\n",
    "    for line in nx.readwrite.gexf.generate_gexf(tt):\n",
    "        output_file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9: Chronotopes I\n",
    "\n",
    "chronotope_graph(root, chronotope)\n",
    "\n",
    "with open('files/graphs/' + chronotope_output_file_name, 'w') as output_file:\n",
    "    for line in nx.readwrite.gexf.generate_gexf(chronotope):\n",
    "        output_file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['public square', 'road', 'provincial town', 'castle', 'metanarrative', 'anti-idyll', 'idyll', 'threshold', 'parlour', 'wilderness', 'encounter']\n",
      "metanarrative\n",
      "threshold\n",
      "wilderness\n",
      "public square\n",
      "parlour\n",
      "castle\n",
      "encounter\n",
      "provincial town\n",
      "idyll\n",
      "anti-idyll\n",
      "road\n"
     ]
    }
   ],
   "source": [
    "# 10: Chronotopes II\n",
    "chronotope_ii = nx.DiGraph()\n",
    "\n",
    "with open('files/xml/' + input_file_name) as fp:\n",
    "    soup = BeautifulSoup(fp)    \n",
    "\n",
    "chronotope_graph_ii(soup, chronotope_ii)\n",
    "\n",
    "with open('files/graphs/' + chronotope_II_output_file_name, 'w') as output_file:\n",
    "    for line in nx.readwrite.gexf.generate_gexf(chronotope_ii):\n",
    "        output_file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutEdgeView([('threshold', 'parlour'), ('threshold', 'anti-idyll'), ('threshold', 'idyll'), ('threshold', 'road'), ('threshold', 'threshold'), ('threshold', 'public square'), ('threshold', 'castle'), ('parlour', 'threshold'), ('parlour', 'public square'), ('parlour', 'idyll'), ('parlour', 'castle'), ('parlour', 'parlour'), ('parlour', 'road'), ('public square', 'threshold'), ('public square', 'public square'), ('castle', 'road'), ('castle', 'parlour'), ('castle', 'public square'), ('castle', 'threshold'), ('castle', 'encounter'), ('road', 'castle'), ('road', 'road'), ('road', 'parlour'), ('road', 'wilderness'), ('road', 'threshold'), ('wilderness', 'road'), ('anti-idyll', 'anti-idyll'), ('anti-idyll', 'road'), ('metanarrative', 'encounter'), ('metanarrative', 'metanarrative'), ('encounter', 'idyll'), ('idyll', 'idyll'), ('idyll', 'castle'), ('idyll', 'threshold'), ('idyll', 'metanarrative'), ('idyll', 'parlour')])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nx.write_gml(chronotope_ii, \"test.gml\")\n",
    "\n",
    "chronotope_ii.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['threshold',\n",
       " 'parlour',\n",
       " 'public square',\n",
       " 'castle',\n",
       " 'road',\n",
       " 'wilderness',\n",
       " 'anti-idyll',\n",
       " 'metanarrative',\n",
       " 'encounter',\n",
       " 'idyll']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(chronotope_ii.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11: Chronotopes III\n",
    "\n",
    "chronotope_iii = nx.DiGraph()\n",
    "\n",
    "chronotope_graph_iii(root, chronotope_iii)\n",
    "\n",
    "with open('files/graphs/' + chronotope_III_output_file_name, 'w') as output_file:\n",
    "    for line in nx.readwrite.gexf.generate_gexf(chronotope_iii):\n",
    "        output_file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
